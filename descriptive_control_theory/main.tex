\documentclass[10pt]{article}
\usepackage{amssymb,amsthm,hyperref}
\usepackage[ruled,lined,boxed,commentsnumbered,linesnumbered]{algorithm2e}
\hypersetup{
    colorlinks,%
    citecolor=blue,%
    filecolor=blue,%
    linkcolor=blue,%
    urlcolor=blue
}

\newcommand{\lrf}{\mathcal{L}_{\mathbb{R}_{\mathcal{F}}}}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{goal}{Goal}

\renewcommand\qedsymbol{$\blacksquare$}


\setlength{\textwidth}{5.5in}
\setlength{\oddsidemargin}{0.5in}

\title{\bf Descriptive Control Theory}
\author{Sicun Gao}
\date{}

\begin{document}
\maketitle
\thispagestyle{empty}

\begin{abstract}
Digital computing units are part of almost every piece of complex machinery around us, from airplanes to cardiac pacemakers to nuclear plants. These applications of computing act as controllers of dynamical systems, and physically engage humans in safety-critical ways. Ensuring correctness-by-construction of these systems requires a rigorous foundation for the design methods of these systems, which are studied in the realm of control theory. I propose the systematic study of the logical and computational foundation for control theory. I use the name ``descriptive control theory” to emphasize the overarching theme of using logic to express, analyze, and solve problems in control theory.
\end{abstract}

\vspace{1cm}

\section{Introduction}

To engineer a system is, ideally, to prove a theorem. While for software systems such a claim can be made almost exact in the sense of Curry-Howard, it may seem semantically vacuous when we consider the engineering of ``real world" systems. Admittedly, the study of formal methods for real-time, hybrid, and cyber-physical systems has made logic an increasingly important part of real-world system engineering, mostly in the form of posterior verification. However, the core methodology of designing real-world systems, which has control theory at its core, has remained largely unchanged. The result of this division is that the merging of information processing 

 the core of engineering practice  much attention is 


The fact that this statement is far from being accepted in general is that there is something wrong with engineering methods. Indeed, engineering is an activity that comes way before logic and computation, in much the same way as mathematics itself. The reflection, using state of the art logic and computation tools, on engineering will bring an even more significant change in science and technology. The goal of this proposal is change that situation, and to set the foundations for applying this slogan to the broadly considered notion of engineering in the ``real" world: to successfully build a reliable real-world system, be it an airplane, a surgery robot, a nuclear plant, is, ultimately, to establish the truth of logic sentences over the real numbers, which is a process that may be automated and made reliable by computational logic. 

Unlike in the digital world, where logic lies at the core of everything, engineering is around way before we can reflect about theorem proving. The fundamental challenge is thus to carry the material in engineering, whose rigorous part is based on control theory, under the lens of logic. Yet this is not just going backward to fit things into a new language. The benefit of doing this brings the computational power and formal rigor of logic-based methods to this domain, which will be able to handle combinations of digital and analogue systems, nonlinear systems, etc. 

Logic lies at the indisputable core of how we process symbolic systems, and the information revolution. Logic lies the basic rules of creation and the mechanism, in many sense industrialization, of how we process this world. People use, implicitly or explicitly, logic to construct the symbolic world. This creation of the digital world is making its inevitable turn back to the physical world. As the start in this century, robots, smart cars, surgical robots, cardiac pacemakers, all are making computation, and thus logic, into part of our environment, and ourselves. The continuous world, however, is not part of what logic has been dealing with. As a result, new objects become non-smooth, mixed analog and digital. One would imagine that if there is a way of making things into logic, this separation would be unnecessary and a unified methodology of making things. This is gaining more importance if we consider the fact that logic brings automation of creation of these processes, with the usual reliability guarantee. The methodology is thus important ...

A methodology analyzes the future of a process and find ways of regulating it to satisfy a certain need. The continuous world has seemed alien to the realm of logic and symbolic methods. Difficulty starts its reflection in dealing with the first-order theory of real arithmetic with trigonometric functions. Consider the simplest question of whether a continuous process, usually governed by some differential equation $\dot{x} = f(x,t)$, can exhibit a certain behavior. A direct expression of such a question would be a formula such as follows
\begin{eqnarray}
\exists x_0 \exists t \exists x_t\; \bigg(x_0 = 0 \;\wedge\; x_t = x_0 + \int_{0}^t f(x(s),s)\mathrm{d}s\; \wedge\; x_t = 1\bigg).
\end{eqnarray}
Answering such questions in general would require a method for deciding $\Sigma_1$-sentences in this logic, which would require us to contain all functions that are needed for expressing continuous processes. Going further from here, recall the attempt of incorporating digital switches in this process. This is apparently very hard~\cite{}. However, a simple reflection of the practice in reality gives as the following idea. Instead of deciding the formula precisely, all we really need to know is whether 
\begin{eqnarray}
\exists x_0 \exists t \exists x_t\; \bigg(|x_0| \leq \delta_1 \;\wedge\; |x_t - (x_0 + \int_{0}^t f(x(s),s)\mathrm{d}s)| \leq \delta_2\; \wedge\; |x_t - 1|\leq \delta_3\bigg).
\end{eqnarray}
for some $\delta$ that is agreed for the context. It would then appear that if we have a way of reasoning about the relaxation of such formulas, or even compute answers for them, we would have a natural way of dealing with the continuous problems, which does not violate any practical concerns. In this way, we realize that solving the problem is almost the same as deciding sigma-1 sentences in this logic, if that can be defined precisely. 

This is indeed the direction that we are setting in this domain and we have prepared a theoretical basis and practical start for it. This is the theory of $\delta$-decisions over real numbers~\cite{}. We change the standard decision problem, which asks whether a sentence is true or false, to the version that asks whether a sentence is true or its ``delta-strengthening" is false. With this change, the decision problem for logic formulas with arbitrary numerically computable functions becomes decidable in bounded domains. The complexity... 

These results naturally bridge the gap and give us tools for dealing with the real questions about continuous or hybrid processes. The goal of this proposal is to set the direction to take off. 
Control theory, just like other theories from a logical perspective, is just a set of sentences that are true under sme interpretation. The significance is that a theorem would correspond to system that is working, which means that a process satisfies some specification. To engineer a system is to find a true theorem, although one may not have a proof of it. Thus once we have the logic working, we naturally have three types of questions to ask, which will be the three main themes of the proposal. They are: how difficult is it to do a certain task? How difficulty is it to prove the correct understanding of a fact? In light of, or using, the complexity classes, are there natural ways of automating them?

I take these to be the core themes of descriptive control theory. I propose to systematically study the logical and computational foundation for control theory. I use the name ``descriptive control theory" to emphasize the overarching theme of using logic to express, analyze, and solve problems in control theory. The study consists of three main components:
\begin{itemize}
\item {\bf Descriptive Complexity.} The first component is to understand the inherent complexity of problems in control theory. I propose the descriptive complexity approach: define a suitable logical language to express the control problems, such that their ``practical" computational complexity can be easily derived through the descriptions. Here, the measure of ``practical" complexity is defined based on our recent work on {\em $\delta$-decisions} of logic formulas over the reals~\cite{DBLP:conf/lics/GaoAC12,DBLP:conf/cade/GaoAC12}, which we will give more details below. 
\item {\bf Logical Foundation.} The second component is to seek a logical foundation for existing theorems and methods in control theory. A natural approach is to follow the program of reverse mathematics, i.e., to characterize control theory in suitable subsystems of second-order arithmetic. Such a foundation would also reveal computational content in these theorems. Moreover, the proofs should be formalized in an interactive theorem prover and can become the basis for formal verification of practical instances of controller design. 
\item {\bf Computational Engine.} The third component is to develop practical decision procedures for the logic formulas involved, which can serve as general algorithms for solving the control problems. As logical decision procedures usually target at hard problems (NP-hard and beyond), they may significantly extend existing methods in control theory, which mostly rely on polynomial-time matrix operations. Moreover, the decision procedures should always produce proofs that can certify correctness of the answers, through interactive theorem provers. 
\end{itemize}
In what follows I will first cover the background, and then explain the three goals in turn. 

\newpage

\section{Background}

\subsection{Delta-Decidability over the Reals} 

Logical approaches are rare for control theory. An obvious obstacle is that solving control problems requires reasoning over the real numbers and functions. The theory of real arithmetic plus trigonometric functions is already highly undecidable, and thus most topics in control theory appear beyond the reach of logical methods. Our approach bypasses this difficulty by studying {\em $\delta$-decisions over the reals}~\cite{DBLP:conf/lics/GaoAC12}. We studied the first-order language $\lrf^1$ over the real numbers, which allows the use of arbitrary Type 2 computable functions. This language is rich enough for expressing a wide range of continuous and hybrid systems and their properties. For instance, consider a dynamical system defined by the differential equation $\dot{x}(t) = f(x(t),t)$ with $x(0)= 0$, where $f$ is Lipschitz-continuous. The reachability question of whether ``the system can reach $x(t)=1$ at some time point $t$" is equivalent to asking whether the following $\mathcal{L}^1_{\mathbb{R}_{\mathcal{F}}}$-formula is true:
\begin{eqnarray*}\exists x_0 \exists t \exists x_t\; \bigg(x_0 = 0 \;\wedge\; x_t = x_0 + \int_{0}^t f(x(s),s)\mathrm{d}s\; \wedge\; x_t = 1\bigg).\end{eqnarray*}
Here the integral is a Type 2 computable term. 

Our approach bypasses this difficulty by studying {\em $\delta$-decisions over the reals}~\cite{DBLP:conf/lics/GaoAC12}. We studied the first-order language $\lrf^1$ over the real numbers, which allows the use of arbitrary Type 2 computable functions. This language is rich enough for expressing a wide range of continuous and hybrid systems and their properties. For instance, consider a dynamical system defined by the differential equation $\dot{x}(t) = f(x(t),t)$ with $x(0)= 0$, where $f$ is Lipschitz-continuous. The reachability question of whether ``the system can reach $x(t)=1$ at some time point $t$" is equivalent to asking whether the following $\mathcal{L}^1_{\mathbb{R}_{\mathcal{F}}}$-formula is true:
\begin{eqnarray*}\exists x_0 \exists t \exists x_t\; \bigg(x_0 = 0 \;\wedge\; x_t = x_0 + \int_{0}^t f(x(s),s)\mathrm{d}s\; \wedge\; x_t = 1\bigg).\end{eqnarray*}
Here the integral is a Type 2 computable term. We showed how to concentrate on the ``practical" complexity of such undecidable formulas, in the sense that the decisions can allow certain types of numerical errors:
\begin{definition}[$\delta$-Decisions~\cite{DBLP:conf/lics/GaoAC12}] Let $\varphi$ be an $\lrf^1$-sentence and $\delta$ a positive rational number. The $\delta$-decision problem asks for one of the following answers: ``$\varphi$ is false" or ``$\varphi^{\delta}$ is true." Here $\varphi^{\delta}$ is a syntactic variant of $\varphi$, defined by relaxing some constant terms in $\varphi$ by numerical errors bounded by $\delta$. 
\end{definition}
\begin{theorem}[$\delta$-Decidability and Complexity~\cite{DBLP:conf/lics/GaoAC12}] The $\delta$-decision problem for arbitrary bounded sentences in $\lrf^1$ is decidable. Moreover, for classes of bounded sentences whose terms are in Type 2 complexity class $\mathsf{C}$, the complexity of $\Sigma_k$-sentences in $\lrf^1$ resides in ${\sf (\Sigma^P_k)^C}$. 
\end{theorem}
It follows immediately that the bounded reachability problem above resides in ${\sf NP^C}$ when $\int_{0}^t f(x(s),s)\mathrm{d}s$ is in ${\sf C}$, and the unbounded version is in ${\sf \Sigma^0_1}$. We have also developed algorithms for solving such formulas~\cite{DBLP:conf/fmcad/GaoKC13}. These results are the basis of using logical methods to analyze control problems and design algorithms at the same time. 

We showed how to concentrate on the ``practical" complexity of such undecidable formulas, in the sense that the decisions can allow certain types of numerical errors:

\begin{definition}[$\delta$-Variants]
Let $\delta\in \mathbb{Q}^+\cup\{0\}$, and $\varphi$ a bounded $\mathcal{L}_{\mathcal{F}}$-sentence of the form
$$Q_1^{I_1}x_1\cdots Q_n^{I_n}x_n.\psi[t_i>0; t_j\geq 0],$$
where $i\in\{1,...k\}$ and $j\in\{k+1,...,j\}$. The {\em $\delta$-strengthening} $\varphi^{+\delta}$ of $\varphi$ is defined to be the result of replacing each atomic formula $t_i > 0$ by $t_i > \delta$ and each atomic formula $t_j \geq 0$ by $t_j \geq \delta$, that is,
$$Q_1^{I_1}x_1\cdots Q_n^{I_n}x_n.\psi[t_i>\delta; t_j\geq \delta],$$
where $i\in\{1,...k\}$ and $j\in\{k+1,...,j\}$.
Similarly, the {\em $\delta$-weakening} $\varphi^{-\delta}$ of $\varphi$ is defined to be the result of replacing each atomic formula $t_i > 0$ by $t_i > -\delta$ and each atomic formula $t_j \geq 0$ by $t_j \geq -\delta$, that is,
$$Q_1^{I_1}x_1\cdots Q_n^{I_n}x_n.\psi[t_i>-\delta; t_j\geq -\delta].$$
\end{definition}
Note that in the definition, the bounds on the quantifiers are not changed. 
\begin{definition}[$\delta$-Decisions~\cite{DBLP:conf/lics/GaoAC12}] Let $\varphi$ be an $\lrf^1$-sentence and $\delta$ a positive rational number. The $\delta$-decision problem asks for one of the following answers: ``$\varphi$ is false" or ``$\varphi^{\delta}$ is true." Here $\varphi^{\delta}$ is a syntactic variant of $\varphi$, defined by relaxing some constant terms in $\varphi$ by numerical errors bounded by $\delta$. 
\end{definition}
\begin{theorem}[$\delta$-Decidability and Complexity~\cite{DBLP:conf/lics/GaoAC12}] The $\delta$-decision problem for arbitrary bounded sentences in $\lrf^1$ is decidable. Moreover, for classes of bounded sentences whose terms are in Type 2 complexity class $\mathsf{C}$, the complexity of $\Sigma_k$-sentences in $\lrf^1$ resides in ${\sf (\Sigma^P_k)^C}$. 
\end{theorem}
It follows immediately that the bounded reachability problem above resides in ${\sf NP^C}$ when $\int_{0}^t f(x(s),s)\mathrm{d}s$ is in ${\sf C}$, and the unbounded version is in ${\sf \Sigma^0_1}$. We have also developed algorithms for solving such formulas~\cite{DBLP:conf/fmcad/GaoKC13}. These results are the basis of using logical methods to analyze control problems and design algorithms at the same time. 

\newpage
\subsection{Control Theory} 

Control theory is the study of ways of regulating dynamical systems and properties of these dynamical systems under regulation. 

We will study two types of problems in control theory. 
\begin{itemize}
\item One is for solving properties of a system, mostly properties regarding reachability, stability, controllability, and observability. 
\item The other one is to come up with controllers that satisfy specifications. Note that stabilization lies at the core of control theory, as many problems can be reduced to stabilizing an error to zero. 
\end{itemize}
The main body of control theory is on linear constant dynamics, which is the result of the methodology of using analytic solutions to reason about systems. Modern control theory has worked out a beautiful theory that reduces control problems to matrix operations. As an example, the behavior of a linear system is completely determined by the eigenvalues of its matrix. Well established conditions are available for determining the controllability, observability for linear systems as well. For instance, the well-known Karman criteria for controllability is as follows. 
\begin{example}

\end{example}

There are two scenarios where existing control theory has difficulty with. One is nonlinear problems, the other is the combination of digital and analog systems, which are so called hybrid systems. Most of the work for nonlinear systems, or systems with uncertainty, is based on the approach of Lyapunov. Basically, to prove the stability of a system, one has to come up with an energy function that monotonically decreases. The search for such functions, however, is hard. The computational issues underlying this search is usually unclear.~\cite{}

In terms of control design, the scenario is similar. We have clear methodology for dealing with purely linear systems, but have great difficulty in handling systems with nonlinear behavior and discrete components. Optimal control, for instance, is the field studying the design of controllers that can achieve a certain goal while keeping some cost at a minimal level. 

The methodology that will be developed in this project will cover nonlinear and hybrid systems. While existing research can be regarded as algorithms for specific subclasses of the problems, the general idea is to give a definite categorization and generic methods for solving the problems. The ultimate goal combines automation and certification: when the solving process is mechanized, checking the correctness of the mechanism becomes a simpler way of ensuring the correctness of the results. 

\newpage

\subsection{Computational Framework}

The theory of delta-decidability now only defines a new perspective to look at decision problems over the reals, but also a way of obtaining concrete algorithms for solving the delta-decision problems, which we say are delta-complete if they provide the correctness guarantee. We have formally analyzed constraint solving algorithms, interval constraint propagation, and show that they provide delta-complete decision procedures when used in the DPLL(T) way. 

We have developed a solver dReal that solves nonlinear formulas over the reals, under the theory of delta-complete decision procedures. We have solved the Kepler conjecture benchmarks, hybrid system benchmarks with hundreds of ODEs, and solved realistic benchmarks by control engineers in Toyota labs~\cite{}. 

We will also touch on the problem of deriving formal proofs for control theory. Here there are two types of formal proofs. One is the kind that we need to manually understand the proofs and encode them into Coq. The other is the theorems that encode the correctness of a real system design. Ideally, those should be the theorems that are derived from the basic theorems of the first type. A major way of deriving the second category of theorems can be automatic generation from decision procedures. In our solver dReal, we provide such capacity of generating formal proofs of theorems. Such proofs are output in a format that can be directly used in a proof assistant. 

Nonlinear solver dReal (\url{http://dreal.cs.cmu.edu}) since late 2012, which has grown into a team of around 10 collaborators (\url{http://github.com/dreal}). dReal has been successfully applied to many problems such as theorem proving~\cite{}, control system design~\cite{}, biology~\cite{}, etc. The tool base will provide a solid basis for implementing the computational goals in the project. 



\newpage
\section{Descriptive Complexity}

The first goal is to encode standard problems in control theory in a first-order theory and have a logical description of control theory. This step is the basis for both a logical foundation and a computational treatment of the problems. An immediate utility of doing this, following the theory of delta-decisions over the reals, is that upper bounds on the complexity of these problems become immediately clear. For instance, we ask what is the complexity of deciding stability of a system, what is the complexity of coming up with an optimal design to achieve a goal. Such questions have not been answered for most of the problems in general. 

For control design problems, the goal is usually to find a function that satisfies certain goals. These problems are most naturally expressed with second-order quantification, which is the motivation for investigating second-order theories written in $\lrf^2$. 

In what follows I will explain the approach taken by the delta-decision, and then the perspectives on extending to second-order formalism. 

\paragraph{Related Work.} Existing work on complexity of control problems have been focusing on giving lower bounds to problems with simple systems. NP-hardness is usually the end of a line of investigation, as it is regarded as giving a definite answer for the non algorithmic solution of a problem. Driven by advances in decision procedures, we do not take this view, and focus on giving a precise characetration of the upper bounds on the problems. The computational nature of stability properties has been a topic of much recent investigation~\cite{DBLP:journals/corr/AhmadiP13,DBLP:journals/automatica/BlondelT99,DBLP:journals/automatica/BlondelT00,AAAthesis,DBLP:conf/hybrid/PrabhakarV13,DBLP:journals/corr/abs-1210-7420}. A focus of existing work is to establish various hardness results, i.e., lower bounds on complexity. It is shown that stability of simple systems is hard or impossible to solve algorithmically. Such results are proved by reducing combinatorial problems over graphs or matrices to stability problems, which can be analyzed with techniques of standard complexity theory. A limitation is that reduction techniques are usually not suitable for establishing upper bounds on complexity, and indeed most questions about upper bounds are open~\cite{AAAthesis}. 

\subsection{Descriptive Complexity in $\lrf^1$} 

The majority of control problems ask for real functions that satisfy certain properties. 

We need to justify the focus on the $\delta$-perturbed version of the problems. The ability of reasoning with both $\delta$-weakening and delta-strengthening gives us the ability of choosing the right perturbation to use. 
\begin{itemize}
\item For the problems that are concerned with a positive property, such as stability, controllability, observability, the perturbation on the negative side strengthens the problems, and are in fact the problems that we would like to solve, rather than the precise ones. 
\item For problems that are concerned with finding a witness such that some property holds, such as an optimal controller, it is more important to solve the perturbation on the positive side. The interpretation would be that the synthesized plan 
\end{itemize}

The study of stability properties of dynamical systems, for instance, can be fully described in $\lrf^1$. Here is an example of how this approach can be applied, with more details in~\cite{DBLP:journals/corr/GaoKC14}. 
\begin{example}
Following standard definition, a system is stable i.s.L. if given any $\varepsilon$, there exists $\delta$ such that for any initial value $x_0$ that is within $\delta$ from the origin, the system stays in $\varepsilon$-distance from the origin. Naturally, the $\lrf$-representation of stability in the sense of Lyapunov is encoded in the following way:
\begin{quote}
\vspace{-.5cm}
\begin{definition}[{\sf L\_stable}]
We define the $\lrf^1$-formula {\sf L\_stable} to be:
\begin{eqnarray*}
& &\forall^{[0,\infty)} \varepsilon\exists^{[0,\varepsilon]} \delta \forall^{[0,\infty)} t\forall x_0\forall x_t .\; (||x_0||<\delta \wedge x_t = \int_0^t f(s)ds + x_0 )\rightarrow ||x_t||<\varepsilon.
\end{eqnarray*}
The {\em bounded form} of {\sf L\_stable} is defined by bounding the quantifiers as:\begin{eqnarray*}
& &\forall^{[0, e]} \varepsilon\exists^{[0,\varepsilon]} \delta \forall^{[0,T]} t\forall^X x_0\forall^X x_t. \;(||x_0||<\delta \wedge x_t = \int_0^t f(s)ds + x_0 )\rightarrow ||x_t||<\varepsilon, 
\end{eqnarray*}
where $e, T\in \mathbb{R}^+$ and $X$ is a compact set.
\end{definition}
\end{quote}
We can then define the $\delta$-stability problem using the $\lrf$-representation:  
\begin{quote}
\vspace{-.5cm}
\begin{definition}[$\delta$-Stability i.s.L.]\label{sl}
The $\delta$-stability problem i.s.L. asks for one of the following answers:
\begin{itemize}
\item {\sf stable}: The system is stable i.s.L. ({\sf L\_stable} is true). 
\item {\sf $\delta$-unstable}: Some $\delta$-perturbation of {\sf L\_stable} is false. 
\end{itemize}
\end{definition}
\end{quote}
We defined the {\em bounded} $\delta$-stability problem by replacing {\sf L\_stable} with the bounded form of {\sf L\_stable} in the definition. Now, using the complexity of the formulas, we have the following complexity results for the bounded version of Lyapunov stability. 
\begin{quote}
\vspace{-.5cm}
\begin{theorem}[Complexity]
Suppose all terms in the $\lrf$-representation of a system are in Type 2 complexity class $\mathsf{C}$.  Then the bounded $\delta$-stability problem i.s.L. resides in complexity class $\mathsf{(\Pi^P_3)^C}$. 
\end{theorem}
\end{quote}
This completes the example of obtaining complexity.\qed
\end{example}
Note that in the example, the new problems are defined through delta-perturbations of their logical encoding. Thus the new definitions are dependent on the descriptive approach. 

The same methodology can be extended to a wide range of topics in control theory. 

Major fields in control design can all be characterized in this way. Optimal, robust, adaptive control design, which are themselves fields in control theory, provides plenty of opportunity for descriptive formalization. By abstracting away the specific techniques, it helps to characterize the different problems and their different algorithms as specific methods for solving the logic formulas. 

\subsection{Descriptions in $\lrf^2$} 

Expressing such problems in full requires a second-order language that naturally extends $\lrf^1$ with second-order quantifiers, which we call $\lrf^2$. For instance, consider the problem of finding an optimal controller for a system $\dot x = f({x}, u)$, with a cost function $g(x(t),u(t))$. Such a controller exists if the following $\lrf^2$-formula is true:
\begin{eqnarray*}
& &\exists U \forall U' \forall {x_0}\forall {x_t} \forall {x_t'}\\
& &\Bigg( \Big({x_t} = {x_0} + \int_{0}^t f({x}(s),U(s))\mathrm{d}s \wedge\;  x_t' = x_0 + \int_{0}^t f(x(s),U(s))\mathrm{d}s
\;\wedge\; \phi(x_0, x_t) \;\wedge\; \phi(x_0, x_t')\Big)\\
& &\hspace{6.5cm}\rightarrow \Big(\int_0^t g(x(s),U(s))\mathrm{d}s \leq  \int_0^t g(x(s),U'(s))\mathrm{d}s)\Big) \Bigg).
\end{eqnarray*}
$U$ and $U'$ denote control functions, and $\phi$ encodes some constraints on the initial and end states. The formula states that there exists a control function $U$ such that any other control function $U'$ that achieves the same goals would cost more than $U$, with respect to the cost function $g$. 

We have conjectured in~\cite{DBLP:conf/lics/GaoAC12} that the second-order language is still delta-decidable under suitable interpretations, since techniques for proving $\delta$-decidability in the first-order case should apply to arbitrary compact metric spaces. We need to develop complexity analysis for $\lrf^2$, which should systematically extend existing complexity results in computable analysis from real functions to functionals. In all, the two main goals are:

\subsection{Main Goals} 

This part consists of the following two goals. 
\begin{itemize}
\item Express control theory in $\mathcal{L}^2_{\mathbb{R}_{\mathcal{F}}}$ with a suitable interpretation (by choosing appropriate domains for the second-order variables), whose bounded $\delta$-decision problem should be decidable.
\item Develop a descriptive complexity theory for $\lrf^2$-formulas with respect to the $\delta$-decisions, and categorize control problems into complexity classes or computability hierarchies.
\end{itemize}

\newpage
\section{Logical Foundation}

The next task is to develop a logical foundation for main results in control theory. Doing so is important in at least two aspects. Mathematically, a formal foundation of control methods is is a basis for the development in the field. Computationally, formal proofs of the main theorems can be used to construct proofs of correctness of concrete practical system designs. 

The mathematical part, the goal is to work out the basis of control theory in suitable subsystems of second-order arithmetic, following the program of reverse mathematics. The benefit of focusing on weak theories, compared to ZFC or higher, is that we can analyze the proofs such that their computational content becomes clear. Note that the Type 2 computable functions in  $\lrf^2$ are continuous functions that can be easily encoded -- the elementary functions are limits of their Taylor expansions, etc. 

The goal is, on the one hand, to find the core minimal mathematical commitment, and on the other hand, to provide a framework for deriving theorems from existing control theory. 


\paragraph{Related Work. } There are various approaches in providing logic-based approaches to dynamical systems and control theory. Most of the existing work focuses on new expressive languages that can express various behaviors of dynamical systems~\cite{}. A lot of work is devoted to the study of hybrid systems to provide a formal foundation based on automata theory. Most of core of control theory only requires a classical first-order to second-order language. Once the study of the core problems is clear, more language constructs, such as temporal modalities, can be further introduced. 

\subsection{Proof Complexity and Reverse Mathematics} 

It is an interesting question to know the mathematical commitment that we have when proving facts about dynamical systems. Theorems in control theory typically give conditions about when a system satisfies certain control properties. 

There are two sides to control theory. One is the analysis side, and the other is the algebraic side. The proof complexity is reduced in the algebraic side, which imposes stronger assumptions on the structure of the systems, for instance, linear systems represented as matrices. The analysis side requires more mathematical commitment. 

One presumably easy but still interesting first task to tackle is to study the reverse mathematics of the state-space methods in control theory regarding linear dynamical systems. It is almost clear that $\mathsf{RCA}_0$ is enough to develop much of linear algebra~\cite{}. Indeed, as results from proof complexity, restricted forms of many facts from linear algebra, such as the Cayley-Hamilton theorem, have polynomial-time proofs~\cite{}. Still, one interesting task is to develop auxiliary techniques for dealing with matrices explicitly. Most of the control theory for linear dynamical systems are stated in the language of matrices. 
For instance, consider the {\em Kalman test for controllability} as follows. 
\begin{example} The Kalman test for controllability states that 
\begin{quote}
\vspace{-.5cm}
\begin{theorem}An $n$-dimensional linear system $\dot {\bf x} = A{\bf x}+B{\bf u}$ is {\em controllable} iff the {\em Kalman matrix}
$$[B\ AB\ \cdots\ A^{n-1}B]$$
is of rank $n$.
\end{theorem} 
\end{quote}
Similarly, there is the corresponding observability theorem
\begin{quote}
\vspace{-.5cm}
\begin{theorem}
The time invariant system $\dot{x} = Ax$ of order $k$ with the observation vector $y=Cx$ is observable if and only if the {\em observability rest matrix}
$$[C^T A^TC^T \cdots (A^T)^{n-1}C^T]$$
is of rank $n$. 
\end{theorem}
\end{quote}
This is a quite straightforward consequence from the Cayley-Hamilton theorem, and consequently the proof complexity should not be high. \qed
\end{example}
The standard way of encoding such formulas is of course through recursive encoding using pairs. This will most likely destroy structures. How this can be avoided requires some construction. 

The analysis side is usually reasoning about the systems from general solutions and derivatives of them. For instance, consider the Lyapunov method for nonlinear stability as follows. 
\begin{example}
Recall that the definition of stability in the sense of Lyapunov is given by the following $\lrf^1$-formula:
\begin{eqnarray*}
\varphi_S:\ \forall\varepsilon\exists^{[0,\varepsilon]} \delta \forall^{[0,\infty)} t\forall x_0\forall x_t .\; (||x_0||<\delta \wedge x_t = \int_0^t f(s)ds + x_0 )\rightarrow ||x_t||<\varepsilon.
\end{eqnarray*}
A simple case of the Lyapunov method is as follows. Let $V(p,x)$ be a function, parameterized by $p\in \mathbb{R}$, whose partial derivative ${\partial V}/{\partial x}$ is a Type 2 computable function. Let $D$ be the parameter space for $p$ and $X$ be the state space of $x$. We then have the following $\lrf$-formula is a sufficient condition for stability in the sense of Lyapunov
$$\varphi_L:\ \varphi_L:\ \exists p\forall x\; \bigg(V(p,x)\geq 0 \wedge V(p,0) = 0\wedge \frac{\partial V(p,x)}{\partial x}f(x)\leq 0\bigg)$$
That is, the Lyapunov methods is based on the a theorem over the reals
$$\varphi_L\rightarrow \varphi_S$$
The proofs of theorems of this sort usually requires considering a ascending chain... \qed
\end{example}
The analysis side is the main part of most of the established subfields of control theory. 

The classical aspects of control theory is worth investigating as well, which involves more complex analysis, and functional analysis. Many valuable results in this direction have been obtained in the work of Yokoyama~\cite{yoko}. For instance, Yokoyama showed that uniformly convergence of Fourier series for $C^1$-functions and $L^2$-convergence of Fourier series for continuous functions are equivalent to $\mathsf{WKL}_0$ over $\mathsf{RCA}_0$. 

In this perspective, an interesting thing to understand is whether classical control theory has more mathematical commitment than modern control theory. If that is the case, this would be a clear sign of improvement in the development of control theory. 




\subsection{Formal Proofs}

An important part of establishing a logical foundation for control theory is the formalization of the proofs in an interactive theorem prover. The interactive proofs do not necessarily start from the weak subsystems, but the formalization in the previous section will certainly be valuable for the formalization of the proofs. 

Candidate proof assistants include Coq, HOL, Isabel. Both the algebraic side and analysis side of control theory can find basic packages to start with. For instance, as a core theorem in matrix algebra, the Cayley-Hamilton theorem is proved in Coq and HOL.  
\begin{example}
The Cayley-Hamilton theorem states that every square matrix over a commutative ring satisfies its own characteristic equation. The theorem lies at the center of control theory for linear systems. It has been a focus of investigation for formal proofs, and the proof has been formalized in both Coq and HOL. 
The HOL formalization of the theorem\footnote{Full proof is at \url{https://code.google.com/p/hol-light/source/browse/trunk/100/cayley_hamilton.ml?spec=svn145&r=145}} is of the form
\begin{verbatim}
|- !A. msum(0..dimindex(:N)) (\i. char_poly A i %% A mpow i) = mat 0
\end{verbatim}
A Coq formalization of the theorem\footnote{Located at \url{http://coq.inria.fr/pylons/contribs/files/Ssreflect/v8.4/Ssreflect.mxpoly.html\#Cayley_Hamilton}} is of the form:
\begin{verbatim}
Theorem Cayley_Hamilton (R : comRingType) n' (A : 'M[R]_n'.+1) : 
                                              horner_mx A (char_poly A) = 0.
\end{verbatim}
It is the basis of deriving other parts of the theory of linear systems. \qed
\end{example}
Different consideration seems to favor different systems for developing the formalization. HOL has concise formulation, while Coq seems to be attractive to a wider community and would be a good choice for the future steps of the integration into proofs of correctness of control software. An alternative option is the new promising theorem prover named Lean~\cite{}, a new project led by Leonardo de Moura. The design principle is to have a framework that can use automatic solvers at the backend as engines in the proofs at the ground level. Much of mathematics is being developed right now in the framework. The benefit of using Lean is that I can take an active role in developing the theorem prover itself and simplify the process of having the control theory library. Right now, most of the work is accomplished by the team of Leonardo de Moura, Jeremy Avigad, and Soonho Kong, all are close collaborators of mine. Kong is also a key developer in dReal and we have concrete plans of the merging of dReal and Lean. 

Regardless of the choice of the proof environment, the goal is to have a control theory library. An ideal plan is to have a document that develops the core part of control theory in the form of a textbooks, with all theorems and proofs formalized in the proof assistant of choice. This can follow the format of the software foundations book~\cite{}. Theorems in control theory that would be interesting to see a formalization include stability, observability, controllability for linear systems as previously mentioned, Lyapunov theory for nonlinear systems, and various results in optimal, robust, and adaptive control. 

Besides the mathematical value of such formalization, An important use of the formal proofs is computational: these proofs can serve as a basis for formal verification of practical control designs. An interesting question is how to connect proofs of the main theorems to automated proofs of the concrete designs. 

\subsection{Summary of Goals}

\begin{goal}
Categorize theorems in control theory in suitable subsystems of second-order arithmetic. 
\end{goal}
\begin{goal}
Formalize the main contents in control theory in an interactive theorem prover.  
\end{goal}

\section{Computational Engine}

The main benefit of using a logical approach to express and formalize control theory is that it is backed by the use of computational engines. The methodology becomes that we can express a problem formally, and then the problem is solved using decision procedures for the logic theory. In this way, decision procedures for the logic formulas become generic algorithms for the control problems. 

It is important to make sure that existing methods in control theory can be used as partial algorithms for subclasses of these formulas. A challenge is to ensure that algorithms based on matrix operations and convex optimization, for instance, can all be suitably called by the logic solver. To make sure of this in a solver, this requires detailed analysis of the numerical algorithms so that delta-completeness can be ensured. The additional benefit, besides automation, is that these decision procedures should automatically produce witnesses or proofs for their answers, such that the correctness of the full control design can be certified with a formal proof. For sat answers, one can simply plug in the solutions and check the correctness (up to delta-bounded errors). For unsat answers, one has to produce a proof of refutations that have been found by the solver. This requires detailed analysis of numerical algorithms, which we have done partially in~\cite{}, but much more needs to be done. 

What I will propose now is the next step on the solver. A main target is $\Sigma_2$-sentences in $\lrf^1$. The next step is to handle important classes in $\lrf^2$, at least up to the point that the existing algorithms in control design can be used. This involves the use of methods from calculus of variations, dynamic programming, etc. 

An interesting point to note is that the problems here all become generalizations of optimization problems. Scalar optimization problems corresponds to $\exists\forall$ formulas with one single existentially quantified variable. 

Again, all the implementations will be done on top of our solver dReal. 

\newpage
\subsection{From $\Sigma_1$ to $\Sigma_2$ Problems} 

As mentioned in the background section, we have developed the framework of {\em $\delta$-decision procedures} for solving $\Sigma_1$-sentences in $\lrf^1$~\cite{DBLP:conf/cade/GaoAC12}, and implemented a practical solver dReal based on the theory. The tool has solved many challenging problems related to control and verification of hybrid systems (see Appendix~\ref{}). Many standard control-theoretic problems, such as the validation of Lyapunov functions for nonlinear systems can be straightforwardly encoded as $\Sigma_1$-sentences, for which dReal has already been used in practical problems~\cite{}. An immediate goal is to have a dedicated environment for solving control problems, which can be easily built as a front end to dReal. 

The important next step of research is to solve $\Sigma_2$-sentences, which will be able to encode a wide range of general control problems. Such descriptions will be the results from the descriptive complexity part of the project. We consider Lyapunov analysis of systems as an example. 
\begin{example}
The search of Lyapunov functions can be done by fixing a template of Lyapunov functions and search for parameters. 
Let $D$ be the parameter space for $p$ and $X$ be the state space of $x$. We then have the following $\lrf$-formula is a sufficient condition for stability in the sense of Lyapunov
$$\varphi_L:\ \exists p\forall x\; \bigg(V(p,x)\geq 0 \wedge V(p,0) = 0\wedge \frac{\partial V(p,x)}{\partial x}f(x)\leq 0\bigg)$$
If $p$ is a single parameter, the problem can be solved by binary search on $p$. In general, if $p$ is a vector, we need procedures for solving $\Sigma_2$ problems. \qed
\end{example}
General $\Sigma_2$ problems can be seen as a generalization of vector optimization problems.  Decision procedures for such sentences can be developed through recursive calls to the algorithms for the existential sentences, and also exploit existing optimization algorithms:
\begin{itemize}
\item The first one is to use optimization solvers as oracles, and solve problems in the DPLL(T) way. This direction should extend all benefits of existing optimization algorithms. Ideally, this provides a framework that strictly generalizes existing practice in control theory. The key is to formalize the numerical procedures such that delta-completeness is achieved. 
\item The second one is the generic procedure of calling the solver itself recursively. One would need to first leave the existentially quantified variables as free, and solve the universally quantified constraints first. The results are then used for pruning the constraints on the existentially quantified variables. 
\end{itemize}
A challenge in the problem is that when we solve for the innermost universally quantified constraints, we need over-approximation on the values of the negation of the formulas. This requires algorithms for computing under approximations for the real variables. Theoretically, this is not harder than solving based on over approximation, but practical algorithms are yet to be developed. On the other hand, we can formulate a notion of mixing delta strengthening and weakening for applications.
\newpage
\subsection{Towards $\lrf^2$} 

A main part of the research in optimization is devoted to infinite dimensional optimization, i.e., optimization of functionals. Typically one needs to solve partial differential equations for solving such problems. 

The goal is to incorportate dynamical programming, calculus of variations, etc. 


Handling second-order problems would be a significant challenge. We need to start with formalizing existing methods in control theory based on calculus of variations and dynamic programming. Thus, the main goals in this part are:

\begin{example}

\end{example}


\newpage
\subsection{Summary of Goals}

\begin{goal}
Develop practical algorithms for the $\delta$-decision problem of $\exists\forall$-sentences in $\lrf^1$.
\end{goal}
\begin{goal}
Develop a framework for solving $\delta$-decision problems of $\lrf^2$-sentences.
\end{goal}


\section{Summary and Timeline}

I have singled out six goals in the previous paragraphs. We can divide them into theoretical goals and computational goals. They are:

\begin{enumerate}
\item Theoretical Goals
\begin{enumerate}
\item A complete description of main first-order problems in control theory in $\lrf^1$, and characterize the complexity accordingly. In this way standard control problems will be extended to nonlinear and hybrid cases. 
\item Develop a suitable second-order language $\lrf^2$ and prove decidability for control design problems that can be expressed accordingly. 
\item Develop reverse mathematics for control theory problems.
\end{enumerate}
\item Computational Goals
\begin{enumerate}
\item A package for formal proofs of basic theorems in state-space control theory. 
\item A practical solver for $\Sigma_2$ problems in control theory. 
\item A preliminary attempt of developing a framework and initial test cases of second-order problems. 
\end{enumerate}
\end{enumerate}

The deliverable goal is to have one paper for each of the goals in the duration of the project. The theoretical goals and computational goals will proceed in parallel. By the end of the first year (i.e., September 2015) the first task in the theoretical goal and the first and second goal in the list should have paper drafts. By the end of the second year, the first two bullets in each part should be finished with paper drafts, and the last goal in the 

An important focus of the project is on developing a tool that will be important for solving practical engineering problems. Preliminary applications of dReal has already exemplifies the importance of the solver. The work accomplished in the project has the potential of providing a new ground for the development of a new generation of control theory that is solidly based on formal theories, relying on its power of automation and certification. The core technology can start a chain of new tools (languages, development environment, etc.) that will redefine the engineering methodology of the field. An even broader impact is possible on other fields including physical sciences, economics, biomedicine, etc. The investigated problems will lay a foundation for logic and computation to play a major part for new advances in technology and sciences. 


\newpage
\bibliographystyle{abbrv}
\bibliography{ref}

\newpage


\section*{Appendix A}

\begin{algorithm}\label{algo1}
\SetKwData{Left}{left}\SetKwData{This}{this}\SetKwData{Up}{up}
\SetKwFunction{Union}{Union}\SetKwFunction{FindCompress}{FindCompress}
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\Input{Constraints $f_1(x_1,...,x_n)=0,...,f_m(x_1,...,x_n)=0$, initial box $B^0 = I^0_1\times \cdots \times I^0_n$, box stack $S=\emptyset$, and precision $\varepsilon\in \mathbb{Q}^+$.}
\Output{{\sf sat} or {\sf unsat}.}
\BlankLine
$S.\mathrm{push}(B_0)$\;
\While{$S\neq \emptyset$}{\label{while}
$B\leftarrow S.\mathrm{pop}()$ \;
\While{$\exists 1\leq i \leq m, B\neq \mathrm{Prune}(B,f_i)$}{ 
%\For{$j\leftarrow 1$ \KwTo $m$}{
	$B\leftarrow\mathrm{Prune}(B, f_i)$ \;
%	\If{$B=\emptyset$}{break\;}
}
\If{$B\neq \emptyset$}
{\eIf{$\exists 1\leq i\leq n, |I_i|\geq \varepsilon$}{$\{B_1,B_2\}\leftarrow \mathrm{Branch}(B, i)$\;$S.\mathrm{push}(\{B_1,B_2\})$\;}{return {\sf sat}\;}}
}
return {\sf unsat}\;
\caption{High-Level ICP$_{\varepsilon}$ (decision version of Branch-and-Prune)}
\end{algorithm}
%\vspace{-.5cm}
In Algorithm 1, Branch$(B,i)$ is an operator that returns two smaller boxes $B' = I_1\times\cdots\times I_i'\times\cdots\times I_n$ and $B''=I_1\times \cdots\times I_i''\times \cdots\times I_n$, where $I_i\subseteq I_i'\cup I_i''$. To ensure termination it is assumed that there exists some constant $0<c<1$ such that $c\cdot |I_i|\leq |I_i'|$ and $c\cdot |I_i|\leq |I_i''|$ for all $i$.

 %The pruning operation $\mathrm{Prune}(B,f_i)$ will be explained in detail below. 

The key component of the algorithm is the $\mathrm{Prune}(B, f)$ operation. A simple example of a pruning operation is as follows.

In principle, any operation that contracts the intervals on variables can be seen as pruning. However, for correctness we need several formal requirements on the pruning operator in ICP$_{\varepsilon}$. 
\begin{definition}[Well-defined Pruning Operators]\label{well}
Let $\mathcal{F}$ be a collection of real functions, and $\sharp$ be an interval extension operator on $\mathcal{F}$. A {\em well-defined (equality) pruning operator} with respect to $\sharp$ is a partial function $\mathrm{Prune}_{\sharp} : \subseteq \mathbb{BF}\times \mathcal{F}\rightarrow \mathbb{BF}$, such that $\forall f\in \mathcal{F}$, $B,B'\in \mathbb{BF}$, 
\begin{itemize}
\item (W1) $\mathrm{Prune}_{\sharp}(B, f)\subseteq B$;
\item (W2) If $(\mathrm{Prune}_{\sharp}(B,f))\neq \emptyset$, then $0\in \sharp f(\mathrm{Prune}_{\sharp}(B,f))$. 
\item (W3) $B \cap Z_f \subseteq \mathrm{Prune}_{\sharp}(B, f)$;
\end{itemize}
\end{definition}
\begin{theorem}[$\delta$-Completeness of ICP$_{\varepsilon}$]\label{main-theorem}
Let $\delta\in \mathbb{Q}^+$ be arbitrary. We can find an $\varepsilon\in \mathbb{Q}^+$ such that the $\mathrm{ICP}_{\varepsilon}$ algorithm is $\delta$-complete for conjunctive $\Sigma_1$-sentences in $\mathcal{L}_{\mathcal{F}}$ (where $\mathsf{sat}$ is interpreted as $\delta$-$\mathsf{sat}$) if and only if the pruning operator in ICP$_{\varepsilon}$ is well-defined. 
\end{theorem}

We have also studied solving formulas of ODEs. A wide range of problems can be encoded in this logic, for instance
\begin{example}

\end{example}
Let $t_0, T\in \mathbb{R}$ and $g:\mathbb{R}^n\rightarrow \mathbb{R}$ be a Lipschitz-continuous function, i.e., for all $\vec x_1, \vec x_2\in\mathbb{R}^n$, $|g(\vec x_1)-g(\vec x_2)|\leq c||\vec x_1-\vec x_2||$ for some constant $c$. Let $t_0, T\in \mathbb{R}$ satisfy $t_0\leq T$ and $\vec y_0\in \mathbb{R}^n$. An IVP problem is given by 
%{\begin{eqnarray}\label{ivp}
$$\frac{d\vec y}{dt} = g(\vec y(t))\mbox{ and } \ \vec y(t_0) = \vec y_0, \mbox{ where }t\in [t_0, T].$$
%\end{eqnarray}}
where $\vec y: [t_0, T]\rightarrow \mathbb{R}^n$ is called the {\em solution} of the IVP. Consider $\vec y(t)$ as $(y_1(t),...,y_n(t))$, then each component $y_i: [t, T]\rightarrow \mathbb{R}$ is a Type 2 computable function, and can appear in some signature $\mathcal{F}$. In fact, we can also regard $\vec y_0$ as an argument of $y_i$ and write $y_i(t_0, \vec y_0)$. This does not change computability properties of $y_i$, since following the Picard-Lindel\"of representation $\vec y(t) = \int_{t_0}^t g(\vec y(s))ds + \vec y_0$, $y_i(t)$ is only linearly dependent on $\vec y_0$. 

In practice, with an ICP framework, we can exploit interval solvers for IVP problems~\cite{DBLP:journals/amc/NedialkovJC99}, for pruning intervals on variables that appear in constraints involving ODEs. This direction has received much recent attention~\cite{DBLP:conf/sefm/EggersRNF11,DBLP:conf/atva/EggersFH08,DBLP:conf/cp/GoldsztejnMEH10,DBLP:journals/sttt/IshiiUH11}. 
%We aim to extend our formal analysis for showing $\delta$-completeness of solvers in this domain.

%\begin{definition}%[Interval-Based ODE Solving]\label{ode-solve}
Consider the IVP problem defined above, with $\vec y_0$ contained in a box $B_{t_0}\subseteq \mathbb{R}^n$. Let $t_0\leq t_1\leq ...\leq t_m = T$ be a set of points in $[t_0, T]$. An interval-based ODE solver returns a set of boxes $B_{t_1},...,B_{t_m}$ such that 
%\begin{eqnarray*}
$$\forall i\in \{1,...,m\},\; [\vec y(t_i; B_{t_0})] = \{\vec y(t): t_0\leq t\leq t_i, \vec y_0\in B_{\vec y_0}\}\subseteq B_{t_i}.$$
%\end{eqnarray*}
%\end{definition}
%This is the guaranteed behavior of practical interval-based solvers such as~\cite{DBLP:journals/amc/NedialkovJC99}. 
%It is clear that this gives an interval extension of the solutions of the ODEs.
%\begin{proposition}
Now let $y_i: [t_0, T]\times B_0 \rightarrow \mathbb{R}$ be the $i$-th component of the solution $\vec y$ of an IVP problem. Then interval-based ODE solvers compute interval extensions of $y_i$. 
%\end{proposition}
Thus, pruning operators that respect the interval extension computed by interval ODE solvers can be defined. It can be concluded from Theorem~\ref{main-theorem} that ICP$_{\varepsilon}$ is $\delta$-complete for equalities involving ODEs, as long as the pruning operator is well-defined. A simplest strategy is just to prune out any set of points outside the interval extension:
\begin{proposition}[Simple ODE-Pruning]
Let $y_i(t,\vec y_0)$ be the $i$-th component function of an IVP problem. Suppose $\sharp y_i$ is computed by an interval ODE solver. Then the pruning operator $\mathrm{Prune}(I, y_i) = I\cap \sharp y_i(I_t, B_{\vec y_0})$ is well-defined. 
\end{proposition}
%\vspace{-.5cm}






\end{document}




 The focus on it in the past century or so is coming back to 


 symbolic, digital, discrete world. It is often put in contrast with calculus, which governs the core of the world of science and engineering. 

But how in essence are they different? Are there ways of unifying them? The way that we build things? Are they subject to the logical, which is almost the same as computational, investigation? Are such investigations gonna provide a new way of dealing with this system? Are they fundamentally different from what we do in the symbolic world? 

The analogy is, however, abound. The search for a solution in the real world is similar to the search of the search for solution of a discrete problem. 

The rest of the {\em real} world has not been examined... Logical methods are rare in control theory, and in the process of engineering. Yet many problems are logical in its essence. 

The descriptive approach emphasis on using a language to express what we want to do, and use logical and computational methods to analyze and, reliably, automate the task. 

The search of an optimal design is the same as the search of a solution of a logical formula, whose equivalence will be a key fact that we will explain. 

A logical foundation is tightly coupled with computational power, and almost all logical questions have become computationally relevant. 

Logical methods are important in several aspects. Advancement in computational logic has made it clear that logic is not just for finding a foundation, but the path for a high degree of automation and reliability. 
 %Control theory studies methods for regulating the behaviors of dynamical systems to achieve desired goals. Topics include behaviors of dynamical systems with inputs, such as stability, controllability, and observability, and the study of techniques for avhiedesigning controllers, which are functions over time that satisfy certain conditions. Topics include feedback control, optimal control, robust control, etc. There exists mature methods, based on linear algebra and complex analysis, for controlling continuous systems governed by linear differential equations. Problems in nonlinear and hybrid system control are either localized to the linear cases, or remain mostly open. 

An obvious obstacle is that solving control problems requires reasoning over the real numbers and functions. The theory of real arithmetic plus trigonometric functions is already highly undecidable, and thus most topics in control theory appear beyond the reach of logical methods. 

Our first goal is to characterize the descriptive complexity of standard control problems. We need a logic that can encode the problems and map them to complexity classes. The majority of control problems ask for real functions that satisfy certain properties...

The next task is to develop logical theories that can derive the main results in control theory.
The work will be done in suitable subsystems of second-order arithmetic following the program of reverse mathematics. With such weak theories, we can analyze the proofs such that their computational content becomes clear. Note that the Type 2 computable functions in  $\lrf^2$ are continuous functions that can be easily encoded. Theorems in control theory typically give conditions about when a system satisfies certain control properties. For instance, the {\em Kalman test for controllability} states that ``An $n$-dimensional linear system $\dot {\bf x} = A{\bf x}+B{\bf u}$ is {\em controllable} iff the {\em Kalman matrix}
$[B\ AB\ \cdots\ A^{n-1}B]$ is of rank $n$." The mathematical content in control theory mostly consists of linear algebra, complex analysis, and functional analysis. Some valuable results in this direction have been obtained in the work of Yokoyama~\cite{yoko}. For instance, he showed that uniformly convergence of Fourier series for $C^1$-functions and $L^2$-convergence of Fourier series for continuous functions are equivalent to $\mathsf{WKL}_0$ over $\mathsf{RCA}_0$. 

The search for a logical foundation will be accompanied by the formalization of the proofs in an interactive theorem prover. Besides the mathematical value of such formalization, these proofs can serve as a basis for formal verification of practical control designs. In all, the two main goals in this part are:

The third task focuses on the algorithmic value of the framework. With a descriptive approach towards control theory, decision procedures for the logic formulas become generic algorithms for the control problems. Existing methods in control theory can be used as partial algorithms for subclasses of these formulas. Moreover, these decision procedures should automatically produce witnesses or proofs for their answers, such that the correctness of the full control design can be certified with a formal proof.

We have developed the framework of {\em $\delta$-decision procedures} for solving $\Sigma_1$-sentences in $\lrf^1$~\cite{DBLP:conf/cade/GaoAC12}. For handling general control problems, the next step is to solve sentences with alternations of quantifiers. This first-order version corresponds to the standard practice in practical control design: fix a control template and find parameters for the template. Decision procedures for such sentences can be developed through recursive calls to the algorithms for the existential sentences, and also exploit existing optimization algorithms. Handling second-order problems would be a significant challenge. We need to start with formalizing existing methods in control theory based on calculus of variations and dynamic programming. Thus, the main goals in this part are:




