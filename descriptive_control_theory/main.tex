\documentclass[10pt]{article}
\usepackage{amssymb,amsthm,hyperref}
\hypersetup{
    colorlinks,%
    citecolor=blue,%
    filecolor=blue,%
    linkcolor=blue,%
    urlcolor=blue
}

\newcommand{\lrf}{\mathcal{L}_{\mathbb{R}_{\mathcal{F}}}}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{goal}{Goal}

\renewcommand\qedsymbol{$\blacksquare$}


\setlength{\textwidth}{6in}
\setlength{\oddsidemargin}{0.25in}

\title{Descriptive Control Theory}
\author{Sicun Gao}
\date{}

\begin{document}
\maketitle
\thispagestyle{empty}

\section{Introduction}

Ideally, to engineer a system is to prove a theorem. While this rings a bell at the level of computer programs through the exact sense of Curry-Howard correspondence, the majority ``systems" are engineered with methodology that is remotely exemplifying this slogan. Here a theorem is logically construed, as a true sentence in a suitable theory, which expresses that the system satisfies a certain set of specifications. The goal of this proposal is change that situation, and to set the foundations for applying this slogan to the broadly considered notion of engineering in the ``real" world: to successfully build a reliable real-world system, be it an airplane, a surgery robot, a nuclear plant, is, ultimately, to establish the truth of logic sentences over the real numbers, which is a process that may be automated and made reliable by computational logic. 

Unlike in the digital world, where logic lies at the core of everything, engineering is around way before we can reflect about theorem proving. The fundamental challenge is thus to carry the material in engineering, whose rigorous part is based on control theory, under the lens of logic. Yet this is not just going backward to fit things into a new language. The benefit of doing this brings the computational power and formal rigor of logic-based methods to this domain, which will be able to handle combinations of digital and analogue systems, nonlinear systems, etc. 

Logic lies at the indisputable core of how we process symbolic systems, and the information revolution. Logic lies the basic rules of creation and the mechanism, in many sense industrialization, of how we process this world. People use, implicitly or explicitly, logic to construct the symbolic world. This creation of the digital world is making its inevitable turn back to the physical world. As the start in this century, robots, smart cars, surgical robots, cardiac pacemakers, all are making computation, and thus logic, into part of our environment, and ourselves. The continuous world, however, is not part of what logic has been dealing with. As a result, new objects become non-smooth, mixed analog and digital. One would imagine that if there is a way of making things into logic, this separation would be unnecessary and a unified methodology of making things. This is gaining more importance if we consider the fact that logic brings automation of creation of these processes, with the usual reliability guarantee. The methodology is thus important ...

A methodology analyzes the future of a process and find ways of regulating it to satisfy a certain need. The continuous world has seemed alien to the realm of logic and symbolic methods. Difficulty starts its reflection in dealing with the first-order theory of real arithmetic with trigonometric functions. Consider the simplest question of whether a continuous process, usually governed by some differential equation $\dot{x} = f(x,t)$, can exhibit a certain behavior. A direct expression of such a question would be a formula such as follows
\begin{eqnarray}
\exists x_0 \exists t \exists x_t\; \bigg(x_0 = 0 \;\wedge\; x_t = x_0 + \int_{0}^t f(x(s),s)\mathrm{d}s\; \wedge\; x_t = 1\bigg).
\end{eqnarray}
Answering such questions in general would require a method for deciding $\Sigma_1$-sentences in this logic, which would require us to contain all functions that are needed for expressing continuous processes. Going further from here, recall the attempt of incorporating digital switches in this process. This is apparently very hard~\cite{}. However, a simple reflection of the practice in reality gives as the following idea. Instead of deciding the formula precisely, all we really need to know is whether 
\begin{eqnarray}
\exists x_0 \exists t \exists x_t\; \bigg(|x_0| \leq \delta_1 \;\wedge\; |x_t - (x_0 + \int_{0}^t f(x(s),s)\mathrm{d}s)| \leq \delta_2\; \wedge\; |x_t - 1|\leq \delta_3\bigg).
\end{eqnarray}
for some $\delta$ that is agreed for the context (pick $\delta$ as the smallest one across all literals). It would then appear that if we have a way of reasoning about the relaxation of such formulas, or even compute answers for them, we would have a natural way of dealing with the continuous problems, which does not violate any practical concerns. In this way, we realize that solving the problem is almost the same as deciding sigma-1 sentences in this logic, if that can be defined precisely. 

This is indeed the direction that we are setting in this domain and we have prepared a theoretical basis and practical start for it. This is the theory of $\delta$-decisions over real numbers~\cite{}. We change the standard decision problem, which asks whether a sentence is true or false, to the version that asks whether a sentence is true or its ``delta-strengthening" is false. With this change, the decision problem for logic formulas with arbitrary numerically computable functions becomes decidable in bounded domains. The complexity... 

These results naturally bridge the gap and give us tools for dealing with the real questions about continuous or hybrid processes. The goal of this proposal is to set the direction to take off. 
Control theory, just like other theories from a logical perspective, is just a set of sentences that are true under sme interpretation. The significance is that a theorem would correspond to system that is working, which means that a process satisfies some specification. To engineer a system is to find a true theorem, although one may not have a proof of it. Thus once we have the logic working, we naturally have three types of questions to ask, which will be the three main themes of the proposal. They are: how difficult is it to do a certain task? How difficulty is it to prove the correct understanding of a fact? In light of, or using, the complexity classes, are there natural ways of automating them?

I take these to be the core themes of descriptive control theory. I propose to systematically study the logical and computational foundation for control theory. I use the name ``descriptive control theory" to emphasize the overarching theme of using logic to express, analyze, and solve problems in control theory. The study consists of three main components:
\begin{itemize}
\item {\bf Descriptive Complexity. } The first component is to understand the inherent complexity of problems in control theory. I propose the descriptive complexity approach: define a suitable logical language to express the control problems, such that their ``practical" computational complexity can be easily derived through the descriptions. Here, the measure of ``practical" complexity is defined based on our recent work on {\em $\delta$-decisions} of logic formulas over the reals~\cite{DBLP:conf/lics/GaoAC12,DBLP:conf/cade/GaoAC12}, which we will give more details below. 
\item {\bf Axiomatic Foundations. } The second component is to seek a logical foundation for existing theorems and methods in control theory. A natural approach is to follow the program of reverse mathematics, i.e., to characterize control theory in suitable subsystems of second-order arithmetic. Such a foundation would also reveal computational content in these theorems. Moreover, the proofs should be formalized in an interactive theorem prover and can become the basis for formal verification of practical instances of controller design. 
\item {\bf Computational Engine.} The third component is to develop practical decision procedures for the logic formulas involved, which can serve as general algorithms for solving the control problems. As logical decision procedures usually target at hard problems (NP-hard and beyond), they may significantly extend existing methods in control theory, which mostly rely on polynomial-time matrix operations. Moreover, the decision procedures should always produce proofs that can certify correctness of the answers, through interactive theorem provers. 
\end{itemize}
In what follows I will first cover the background, and then explain the three goals in turn. 

\section{Background}

\subsection{Delta-Decidability over the Reals} 

Logical approaches are rare for control theory. An obvious obstacle is that solving control problems requires reasoning over the real numbers and functions. The theory of real arithmetic plus trigonometric functions is already highly undecidable, and thus most topics in control theory appear beyond the reach of logical methods. Our approach bypasses this difficulty by studying {\em $\delta$-decisions over the reals}~\cite{DBLP:conf/lics/GaoAC12}. We studied the first-order language $\lrf^1$ over the real numbers, which allows the use of arbitrary Type 2 computable functions. This language is rich enough for expressing a wide range of continuous and hybrid systems and their properties. For instance, consider a dynamical system defined by the differential equation $\dot{x}(t) = f(x(t),t)$ with $x(0)= 0$, where $f$ is Lipschitz-continuous. The reachability question of whether ``the system can reach $x(t)=1$ at some time point $t$" is equivalent to asking whether the following $\mathcal{L}^1_{\mathbb{R}_{\mathcal{F}}}$-formula is true:
\begin{eqnarray*}\exists x_0 \exists t \exists x_t\; \bigg(x_0 = 0 \;\wedge\; x_t = x_0 + \int_{0}^t f(x(s),s)\mathrm{d}s\; \wedge\; x_t = 1\bigg).\end{eqnarray*}
Here the integral is a Type 2 computable term. 

Our approach bypasses this difficulty by studying {\em $\delta$-decisions over the reals}~\cite{DBLP:conf/lics/GaoAC12}. We studied the first-order language $\lrf^1$ over the real numbers, which allows the use of arbitrary Type 2 computable functions. This language is rich enough for expressing a wide range of continuous and hybrid systems and their properties. For instance, consider a dynamical system defined by the differential equation $\dot{x}(t) = f(x(t),t)$ with $x(0)= 0$, where $f$ is Lipschitz-continuous. The reachability question of whether ``the system can reach $x(t)=1$ at some time point $t$" is equivalent to asking whether the following $\mathcal{L}^1_{\mathbb{R}_{\mathcal{F}}}$-formula is true:
\begin{eqnarray*}\exists x_0 \exists t \exists x_t\; \bigg(x_0 = 0 \;\wedge\; x_t = x_0 + \int_{0}^t f(x(s),s)\mathrm{d}s\; \wedge\; x_t = 1\bigg).\end{eqnarray*}
Here the integral is a Type 2 computable term. We showed how to concentrate on the ``practical" complexity of such undecidable formulas, in the sense that the decisions can allow certain types of numerical errors:
\begin{definition}[$\delta$-Decisions~\cite{DBLP:conf/lics/GaoAC12}] Let $\varphi$ be an $\lrf^1$-sentence and $\delta$ a positive rational number. The $\delta$-decision problem asks for one of the following answers: ``$\varphi$ is false" or ``$\varphi^{\delta}$ is true." Here $\varphi^{\delta}$ is a syntactic variant of $\varphi$, defined by relaxing some constant terms in $\varphi$ by numerical errors bounded by $\delta$. 
\end{definition}
\begin{theorem}[$\delta$-Decidability and Complexity~\cite{DBLP:conf/lics/GaoAC12}] The $\delta$-decision problem for arbitrary bounded sentences in $\lrf^1$ is decidable. Moreover, for classes of bounded sentences whose terms are in Type 2 complexity class $\mathsf{C}$, the complexity of $\Sigma_k$-sentences in $\lrf^1$ resides in ${\sf (\Sigma^P_k)^C}$. 
\end{theorem}
It follows immediately that the bounded reachability problem above resides in ${\sf NP^C}$ when $\int_{0}^t f(x(s),s)\mathrm{d}s$ is in ${\sf C}$, and the unbounded version is in ${\sf \Sigma^0_1}$. We have also developed algorithms for solving such formulas~\cite{DBLP:conf/fmcad/GaoKC13}. These results are the basis of using logical methods to analyze control problems and design algorithms at the same time. 

We showed how to concentrate on the ``practical" complexity of such undecidable formulas, in the sense that the decisions can allow certain types of numerical errors:

\begin{definition}[$\delta$-Variants]
Let $\delta\in \mathbb{Q}^+\cup\{0\}$, and $\varphi$ a bounded $\mathcal{L}_{\mathcal{F}}$-sentence of the form
$$Q_1^{I_1}x_1\cdots Q_n^{I_n}x_n.\psi[t_i>0; t_j\geq 0],$$
where $i\in\{1,...k\}$ and $j\in\{k+1,...,j\}$. The {\em $\delta$-strengthening} $\varphi^{+\delta}$ of $\varphi$ is defined to be the result of replacing each atomic formula $t_i > 0$ by $t_i > \delta$ and each atomic formula $t_j \geq 0$ by $t_j \geq \delta$, that is,
$$Q_1^{I_1}x_1\cdots Q_n^{I_n}x_n.\psi[t_i>\delta; t_j\geq \delta],$$
where $i\in\{1,...k\}$ and $j\in\{k+1,...,j\}$.
Similarly, the {\em $\delta$-weakening} $\varphi^{-\delta}$ of $\varphi$ is defined to be the result of replacing each atomic formula $t_i > 0$ by $t_i > -\delta$ and each atomic formula $t_j \geq 0$ by $t_j \geq -\delta$, that is,
$$Q_1^{I_1}x_1\cdots Q_n^{I_n}x_n.\psi[t_i>-\delta; t_j\geq -\delta].$$
\end{definition}
Note that in the definition, the bounds on the quantifiers are not changed. 
\begin{definition}[$\delta$-Decisions~\cite{DBLP:conf/lics/GaoAC12}] Let $\varphi$ be an $\lrf^1$-sentence and $\delta$ a positive rational number. The $\delta$-decision problem asks for one of the following answers: ``$\varphi$ is false" or ``$\varphi^{\delta}$ is true." Here $\varphi^{\delta}$ is a syntactic variant of $\varphi$, defined by relaxing some constant terms in $\varphi$ by numerical errors bounded by $\delta$. 
\end{definition}
\begin{theorem}[$\delta$-Decidability and Complexity~\cite{DBLP:conf/lics/GaoAC12}] The $\delta$-decision problem for arbitrary bounded sentences in $\lrf^1$ is decidable. Moreover, for classes of bounded sentences whose terms are in Type 2 complexity class $\mathsf{C}$, the complexity of $\Sigma_k$-sentences in $\lrf^1$ resides in ${\sf (\Sigma^P_k)^C}$. 
\end{theorem}
It follows immediately that the bounded reachability problem above resides in ${\sf NP^C}$ when $\int_{0}^t f(x(s),s)\mathrm{d}s$ is in ${\sf C}$, and the unbounded version is in ${\sf \Sigma^0_1}$. We have also developed algorithms for solving such formulas~\cite{DBLP:conf/fmcad/GaoKC13}. These results are the basis of using logical methods to analyze control problems and design algorithms at the same time. 


\subsection{Control Theory} 

Control theory is the study of ways of regulating dynamical systems and properties of these dynamical systems under regulation. 

We will study two types of problems in control theory. One is for solving properties of a system, mostly properties regarding reachability, stability, controllability, and observability. The other one is to come up with controllers that satisfy specifications. Note that stabilization lies at the core of control theory, as many problems can be reduced to stabilizing an error to zero. 

The main body of control theory is on linear constant dynamics, which is the result of the methodology of using analytic solutions to reason about systems. Modern control theory has worked out a beautiful theory that reduces control problems to matrix operations. As an example, the behavior of a linear system is completely determined by the eigenvalues of its matrix. Well established conditions are available for determining the controllability, observability for linear systems as well. For instance, the well-known Karman criteria for controllability. 

There are two scenarios where existing control theory has difficulty with. One is nonlinear problems, the other is the combination of digital and analog systems, which are so called hybrid systems. Most of the work for nonlinear systems, or systems with uncertainty, is based on the approach of Lyapunov. Basically, to prove the stability of a system, one has to come up with an energy function that monotonically decreases. The search for such functions, however, is hard. The computational issues underlying this search is usually unclear.~\cite{}

In terms of control design, the scenario is similar. We have clear methodology for dealing with purely linear systems, but have great difficulty in handling systems with nonlinear behavior and discrete components. Optimal control, for instance, is the field studying the design of controllers that can achieve a certain goal while keeping some cost at a minimal level. 

The methodology that will be developed in this project will cover nonlinear and hybrid systems. While existing research can be regarded as algorithms for specific subclasses of the problems, the general idea is to give a definite categorization and generic methods for solving the problems. The ultimate goal combines automation and certification: when the solving process is mechanized, checking the correctness of the mechanism becomes a simpler way of ensuring the correctness of the results. 

\subsection{Computational Framework}

The theory of delta-decidability now only defines a new perspective to look at decision problems over the reals, but also a way of obtaining concrete algorithms for solving the delta-decision problems, which we say are delta-complete if they provide the correctness guarantee. We have formally analyzed constraint solving algorithms, interval constraint propagation, and show that they provide delta-complete decision procedures when used in the DPLL(T) way. 

We have developed a solver dReal that solves nonlinear formulas over the reals, under the theory of delta-complete decision procedures. We have solved the Kepler conjecture benchmarks, hybrid system benchmarks with hundreds of ODEs, and solved realistic benchmarks by control engineers in Toyota labs~\cite{}. 

We will also touch on the problem of deriving formal proofs for control theory. Here there are two types of formal proofs. One is the kind that we need to manually understand the proofs and encode them into Coq. The other is the theorems that encode the correctness of a real system design. Ideally, those should be the theorems that are derived from the basic theorems of the first type. A major way of deriving the second category of theorems can be automatic generation from decision procedures. In our solver dReal, we provide such capacity of generating formal proofs of theorems. Such proofs are output in a format that can be directly used in a proof assistant. 


\section{Descriptive Complexity}

The first goal is simply to express standard problems in control theory in a first-order theory. The benefit is upper bounds on their complexity can be easily derived. For instance, we ask what is the complexity of deciding stability of a system, what is the complexity of coming up with an optimal design to achieve a goal. Such questions have not been answered for most of the problems in general. We argue that the delta-version of the complexity is the right questions to answer. 

Existing work on complexity of control problems have been focusing on giving lower bounds to problems with simple systems. NP-hardness is usually the end of a line of investigation, as it is regarded as giving a definite answer for the non algorithmic solution of a problem. Driven by advances in decision procedures, we do not take this view, and focus on giving a precise characetration of the upper bounds on the problems. 

In what follows I will explain the approach taken by the delta-decision, and then the perspectives on extending to second-order formalism. 

\subsection{Descriptive Complexity in $\lrf^1$} 

The majority of control problems ask for real functions that satisfy certain properties. 

We need to justify the focus on the $\delta$-perturbed version of the problems. The ability of reasoning with both $\delta$-weakening and delta-strengthening gives us the ability of choosing the right perturbation to use. 
\begin{itemize}
\item For the problems that are concerned with a positive property, such as stability, controllability, observability, the perturbation on the negative side strengthens the problems, and are in fact the problems that we would like to solve, rather than the precise ones. 
\item For problems that are concerned with finding a witness such that some property holds, such as an optimal controller, it is more important to solve the perturbation on the positive side. The interpretation would be that the synthesized plan 
\end{itemize}

The study of stability properties of dynamical systems, for instance, can be fully described in $\lrf^1$. Here is an example of how this approach can be applied, with more details in~\cite{}. 
\begin{example}
Following standard definition, a system is stable i.s.L. if given any $\varepsilon$, there exists $\delta$ such that for any initial value $x_0$ that is within $\delta$ from the origin, the system stays in $\varepsilon$-distance from the origin. Naturally, the $\lrf$-representation of stability in the sense of Lyapunov is encoded in the following way:
\begin{quote}
\vspace{-.5cm}
\begin{definition}[{\sf L\_stable}]
We define the $\lrf^1$-formula {\sf L\_stable} to be:
\begin{eqnarray*}
& &\forall^{[0,\infty)} \varepsilon\exists^{[0,\varepsilon]} \delta \forall^{[0,\infty)} t\forall x_0\forall x_t .\; (||x_0||<\delta \wedge x_t = \int_0^t f(s)ds + x_0 )\rightarrow ||x_t||<\varepsilon.
\end{eqnarray*}
The {\em bounded form} of {\sf L\_stable} is defined by bounding the quantifiers as:\begin{eqnarray*}
& &\forall^{[0, e]} \varepsilon\exists^{[0,\varepsilon]} \delta \forall^{[0,T]} t\forall^X x_0\forall^X x_t. \;(||x_0||<\delta \wedge x_t = \int_0^t f(s)ds + x_0 )\rightarrow ||x_t||<\varepsilon, 
\end{eqnarray*}
where $e, T\in \mathbb{R}^+$ and $X$ is a compact set.
\end{definition}
\end{quote}
We can then define the $\delta$-stability problem using the $\lrf$-representation:  
\begin{quote}
\vspace{-.5cm}
\begin{definition}[$\delta$-Stability i.s.L.]\label{sl}
The $\delta$-stability problem i.s.L. asks for one of the following answers:
\begin{itemize}
\item {\sf stable}: The system is stable i.s.L. ({\sf L\_stable} is true). 
\item {\sf $\delta$-unstable}: Some $\delta$-perturbation of {\sf L\_stable} is false. 
\end{itemize}
\end{definition}
\end{quote}
We defined the {\em bounded} $\delta$-stability problem by replacing {\sf L\_stable} with the bounded form of {\sf L\_stable} in the definition. Now, using the complexity of the formulas, we have the following complexity results for the bounded version of Lyapunov stability. 
\begin{quote}
\vspace{-.5cm}
\begin{theorem}[Complexity]
Suppose all terms in the $\lrf$-representation of a system are in Type 2 complexity class $\mathsf{C}$.  Then the bounded $\delta$-stability problem i.s.L. resides in complexity class $\mathsf{(\Pi^P_3)^C}$. 
\end{theorem}
\end{quote}
This completes the example of obtaining complexity.\qed
\end{example}
Note that in the example, the new problems are defined through delta-perturbations of their logical encoding. Thus the new definitions are dependent on the descriptive approach. 

The same methodology can be extended to a wide range of topics in control theory. 

Major fields in control design can all be characterized in this way. Optimal, robust, adaptive control design, which are themselves fields in control theory, provides plenty of opportunity for descriptive formalization. By abstracting away the specific techniques, it helps to characterize the different problems and their different algorithms as specific methods for solving the logic formulas. 

\subsection{Descriptions in $\lrf^2$} 

Expressing such problems in full requires a second-order language that naturally extends $\lrf^1$ with second-order quantifiers, which we call $\lrf^2$. For instance, consider the problem of finding an optimal controller for a system $\dot x = f({x}, u)$, with a cost function $g(x(t),u(t))$. Such a controller exists if the following $\lrf^2$-formula is true:
\begin{eqnarray*}
& &\exists U \forall U' \forall {x_0}\forall {x_t} \forall {x_t'}\\
& &\Bigg( \Big({x_t} = {x_0} + \int_{0}^t f({x}(s),U(s))\mathrm{d}s \wedge\;  x_t' = x_0 + \int_{0}^t f(x(s),U(s))\mathrm{d}s
\;\wedge\; \phi(x_0, x_t) \;\wedge\; \phi(x_0, x_t')\Big)\\
& &\hspace{6.5cm}\rightarrow \Big(\int_0^t g(x(s),U(s))\mathrm{d}s \leq  \int_0^t g(x(s),U'(s))\mathrm{d}s)\Big) \Bigg).
\end{eqnarray*}
$U$ and $U'$ denote control functions, and $\phi$ encodes some constraints on the initial and end states. The formula states that there exists a control function $U$ such that any other control function $U'$ that achieves the same goals would cost more than $U$, with respect to the cost function $g$. 

We have conjectured in~\cite{DBLP:conf/lics/GaoAC12} that the second-order language is still delta-decidable under suitable interpretations, since techniques for proving $\delta$-decidability in the first-order case should apply to arbitrary compact metric spaces. We need to develop complexity analysis for $\lrf^2$, which should systematically extend existing complexity results in computable analysis from real functions to functionals. In all, the two main goals are:

\subsection{Summary of Goals} 

This part consists of the following two goals. 
\begin{itemize}
\item Express control theory in $\mathcal{L}^2_{\mathbb{R}_{\mathcal{F}}}$ with a suitable interpretation (by choosing appropriate domains for the second-order variables), whose bounded $\delta$-decision problem should be decidable.
\item Develop a descriptive complexity theory for $\lrf^2$-formulas with respect to the $\delta$-decisions, and categorize control problems into complexity classes or computability hierarchies.
\end{itemize}


\section{Axiomatic Foundations}

The next task is to develop logical theories that can derive the main results in control theory.
The work will be done in suitable subsystems of second-order arithmetic following the program of reverse mathematics. With such weak theories, we can analyze the proofs such that their computational content becomes clear. Note that the Type 2 computable functions in  $\lrf^2$ are continuous functions that can be easily encoded -- the elementary functions are limits of their Taylor expansions, etc. 

Previous work. There are various approaches in providing logic-based approaches to dynamical systems and control theory, but they are not what is intended here. Andre's work. Various formalisms for real systems. Discrete dynamical systems. 

The goal is, on the one hand, to find the core minimal mathematical commitment, and on the other hand, to provide a framework for deriving theorems from existing control theory. 

\subsection{Control Theory in Subsystems of Second-Order Arithmetic} 

Theorems in control theory typically give conditions about when a system satisfies certain control properties. For instance, the {\em Kalman test for controllability} states that ``An $n$-dimensional linear system $\dot {\bf x} = A{\bf x}+B{\bf u}$ is {\em controllable} iff the {\em Kalman matrix}
$[B\ AB\ \cdots\ A^{n-1}B]$ is of rank $n$." 

The mathematical content in control theory mostly consists of linear algebra, complex analysis, and functional analysis. Some valuable results in this direction have been obtained in the work of Yokoyama~\cite{yoko}. For instance, he showed that uniformly convergence of Fourier series for $C^1$-functions and $L^2$-convergence of Fourier series for continuous functions are equivalent to $\mathsf{WKL}_0$ over $\mathsf{RCA}_0$. 

$\mathsf{RCA}_0$ is enough to develop much of linear algebra~\cite{}, Exercise II.4.11. 

\subsection{Formalization of Proofs}

The search for a logical foundation will be accompanied by the formalization of the proofs in an interactive theorem prover. The interactive proofs do not necessarily start from the weak subsystems. 


Besides the mathematical value of such formalization, these proofs can serve as a basis for formal verification of practical control designs. 

The following are interesting theorems in control theory. 
\begin{itemize}
\item Control conditions. 
\item Karlman Filters. 
\end{itemize}

\subsection{Summary of Goals}

\begin{goal}
Categorize theorems in control theory in suitable subsystems of second-order arithmetic. 
\end{goal}
\begin{goal}
Formalize the main contents in control theory in an interactive theorem prover.  
\end{goal}



\section{Computational Engines}


The third task focuses on the algorithmic value of the framework. With a descriptive approach towards control theory, decision procedures for the logic formulas become generic algorithms for the control problems. Existing methods in control theory can be used as partial algorithms for subclasses of these formulas. Moreover, these decision procedures should automatically produce witnesses or proofs for their answers, such that the correctness of the full control design can be certified with a formal proof.

\subsection{From $\Sigma_1$ to $\Sigma_2$ Sentences} 

We have developed the framework of {\em $\delta$-decision procedures} for solving $\Sigma_1$-sentences in $\lrf^1$~\cite{DBLP:conf/cade/GaoAC12}. For handling general control problems, the next step is to solve sentences with alternations of quantifiers. This first-order version corresponds to the standard practice in practical control design: fix a control template and find parameters for the template. Decision procedures for such sentences can be developed through recursive calls to the algorithms for the existential sentences, and also exploit existing optimization algorithms. 

There are two ways we can go to solve these formulas. 
\begin{itemize}
\item The first one is to use optimization solvers as oracles, and solve problems in the DPLL(T) way. This direction should extend all benefits of existing optimization algorithms. Ideally, this provides a framework that strictly generalizes existing practice in control theory. The key is to formalize the numerical procedures such that delta-completeness is achieved. 
\item The second one is the generic procedure of calling the solver itself recursively. One would need to solve 
\end{itemize}

This is vector optimization.  

\subsection{Second-order Quantification} 

Handling second-order problems would be a significant challenge. We need to start with formalizing existing methods in control theory based on calculus of variations and dynamic programming. Thus, the main goals in this part are:


\subsection{Summary of Goals}

\begin{goal}
Develop practical algorithms for the $\delta$-decision problem of $\exists\forall$-sentences in $\lrf^1$.
\end{goal}
\begin{goal}
Develop a framework for solving $\delta$-decision problems of $\lrf^2$-sentences.
\end{goal}




\section{Timeline}

A table of timelines and evaluation of the easiness. 












\bibliographystyle{abbrv}
\bibliography{ref}






\end{document}




 The focus on it in the past century or so is coming back to 


 symbolic, digital, discrete world. It is often put in contrast with calculus, which governs the core of the world of science and engineering. 

But how in essence are they different? Are there ways of unifying them? The way that we build things? Are they subject to the logical, which is almost the same as computational, investigation? Are such investigations gonna provide a new way of dealing with this system? Are they fundamentally different from what we do in the symbolic world? 

The analogy is, however, abound. The search for a solution in the real world is similar to the search of the search for solution of a discrete problem. 

The rest of the {\em real} world has not been examined... Logical methods are rare in control theory, and in the process of engineering. Yet many problems are logical in its essence. 

The descriptive approach emphasis on using a language to express what we want to do, and use logical and computational methods to analyze and, reliably, automate the task. 

The search of an optimal design is the same as the search of a solution of a logical formula, whose equivalence will be a key fact that we will explain. 

A logical foundation is tightly coupled with computational power, and almost all logical questions have become computationally relevant. 

Logical methods are important in several aspects. Advancement in computational logic has made it clear that logic is not just for finding a foundation, but the path for a high degree of automation and reliability. 
 %Control theory studies methods for regulating the behaviors of dynamical systems to achieve desired goals. Topics include behaviors of dynamical systems with inputs, such as stability, controllability, and observability, and the study of techniques for avhiedesigning controllers, which are functions over time that satisfy certain conditions. Topics include feedback control, optimal control, robust control, etc. There exists mature methods, based on linear algebra and complex analysis, for controlling continuous systems governed by linear differential equations. Problems in nonlinear and hybrid system control are either localized to the linear cases, or remain mostly open. 

An obvious obstacle is that solving control problems requires reasoning over the real numbers and functions. The theory of real arithmetic plus trigonometric functions is already highly undecidable, and thus most topics in control theory appear beyond the reach of logical methods. 

Our first goal is to characterize the descriptive complexity of standard control problems. We need a logic that can encode the problems and map them to complexity classes. The majority of control problems ask for real functions that satisfy certain properties...

The next task is to develop logical theories that can derive the main results in control theory.
The work will be done in suitable subsystems of second-order arithmetic following the program of reverse mathematics. With such weak theories, we can analyze the proofs such that their computational content becomes clear. Note that the Type 2 computable functions in  $\lrf^2$ are continuous functions that can be easily encoded. Theorems in control theory typically give conditions about when a system satisfies certain control properties. For instance, the {\em Kalman test for controllability} states that ``An $n$-dimensional linear system $\dot {\bf x} = A{\bf x}+B{\bf u}$ is {\em controllable} iff the {\em Kalman matrix}
$[B\ AB\ \cdots\ A^{n-1}B]$ is of rank $n$." The mathematical content in control theory mostly consists of linear algebra, complex analysis, and functional analysis. Some valuable results in this direction have been obtained in the work of Yokoyama~\cite{yoko}. For instance, he showed that uniformly convergence of Fourier series for $C^1$-functions and $L^2$-convergence of Fourier series for continuous functions are equivalent to $\mathsf{WKL}_0$ over $\mathsf{RCA}_0$. 

The search for a logical foundation will be accompanied by the formalization of the proofs in an interactive theorem prover. Besides the mathematical value of such formalization, these proofs can serve as a basis for formal verification of practical control designs. In all, the two main goals in this part are:

The third task focuses on the algorithmic value of the framework. With a descriptive approach towards control theory, decision procedures for the logic formulas become generic algorithms for the control problems. Existing methods in control theory can be used as partial algorithms for subclasses of these formulas. Moreover, these decision procedures should automatically produce witnesses or proofs for their answers, such that the correctness of the full control design can be certified with a formal proof.

We have developed the framework of {\em $\delta$-decision procedures} for solving $\Sigma_1$-sentences in $\lrf^1$~\cite{DBLP:conf/cade/GaoAC12}. For handling general control problems, the next step is to solve sentences with alternations of quantifiers. This first-order version corresponds to the standard practice in practical control design: fix a control template and find parameters for the template. Decision procedures for such sentences can be developed through recursive calls to the algorithms for the existential sentences, and also exploit existing optimization algorithms. Handling second-order problems would be a significant challenge. We need to start with formalizing existing methods in control theory based on calculus of variations and dynamic programming. Thus, the main goals in this part are:




